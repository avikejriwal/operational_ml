## Notebook instance

I chose the default instance (ml.t3.medium) I don't need a lot of computing power to run the notebook itself. The code can deploy the computiationally intensive parts (such as training the model) to other EC3 instances in SageMaker

## EC2 Instance

The EC2 Instance trains the model directly, rather than creating another instance, so I chose a more powerful instance for model training in this case.  Chose to use an 'm5.xlarge' to this end. Ideally I would use a spot instance, but they weren't available for this setup, so I went with a normal provisioned instance instead.

This is very similar to training the model on SageMaker, except this one is a standalone python script training on a single machine, while SageMaker script focuses on provisioning resources within AWS.

## Lambda Function

The lambda function takes in an parameter for the data to run predictions on and then calls the model endpoint from SageMaker to return a prediction. This is similar to API's that are built in other web applications

response: [[-7.316348552703857, -4.659984111785889, -2.2499637603759766, -0.12016993761062622, -3.89392352104187, -6.6806206703186035, 0.8906881809234619, 0.5461301803588867, -2.866894483566284, -0.11474344879388809, -1.6991456747055054, -3.501413345336914, -5.829226493835449, 0.1401931345462799, 0.5076720714569092, 0.3800281882286072, -5.435673236846924, -3.2385902404785156, -1.9086549282073975, 0.6297837495803833, -7.326624393463135, -5.687031269073486, -5.79470682144165, -6.313512802124023, -0.7435914874076843, -3.5620837211608887, 0.9503066539764404, -0.38860592246055603, -7.647252082824707, -3.22404146194458, -2.4076502323150635, 0.08328568935394287, -3.3312137126922607, 0.3123132586479187, -4.852538585662842, -5.45185661315918, -1.841617465019226, -5.924400806427002, 0.3944527208805084, 0.26383766531944275, 0.6074777841567993, -5.8804755210876465, -0.3227664828300476, 1.2835228443145752, 0.11208681762218475, -5.53143310546875, -0.18620872497558594, -0.23544874787330627, -1.921981692314148, 0.40700262784957886, -3.278529405593872, -2.847522020339966, -2.4639854431152344, -4.861918926239014, -3.1882643699645996, 0.04470330476760864, 1.1667964458465576, -5.948491096496582, -1.0308711528778076, 0.6819282174110413, -2.7634689807891846, -2.975034475326538, -3.344661235809326, -6.151089191436768, -1.4482848644256592, -4.344186782836914, -3.3967931270599365, -4.809727191925049, -0.17646050453186035, -0.017493978142738342, -0.5214511752128601, 0.31934988498687744, -2.2250595092773438, -2.8100318908691406, -5.6239399909973145, -3.5363948345184326, -5.197621822357178, 0.15317106246948242, -5.054217338562012, -1.086916208267212, 0.771996259689331, -6.2107672691345215, -0.2632991671562195, -2.024887800216675, -4.247201442718506, -3.935053586959839, -2.0521974563598633, -2.3396105766296387, -2.715017795562744, 0.7005950212478638, -6.314724922180176, -7.77728271484375, -2.299555778503418, -6.378431797027588, -3.232358694076538, -0.2177285999059677, -1.5288262367248535, -3.386918783187866, -5.979013919830322, -5.776595592498779, -5.707764148712158, -0.4144388437271118, 0.08708930015563965, -4.4927449226379395, 0.2607552707195282, -3.5476126670837402, -3.580271005630493, -1.2544045448303223, -2.113065242767334, -0.7560867667198181, -5.362590312957764, -3.133697271347046, -6.506525993347168, -3.316554307937622, -6.39171028137207, 0.38032567501068115, -7.067685127258301, -1.3936904668807983, -7.708642482757568, 0.08801180124282837, 0.06398698687553406, -0.1538170576095581, -5.735414505004883, -2.47296404838562, -4.9153032302856445, -0.8038128614425659, -6.388158321380615, -0.6917755007743835, -5.655838966369629, -3.1387763023376465, -6.739288806915283, -0.19803795218467712, -6.718891620635986]]

## Security

Main concern is adding full SageMaker access to the Lambda role. Maybe if I want to be more stringent then I would restrict that to read-only access, but in this use case it should be okay.

## Autoscaling

Added both reserve and provisioned concurrency on Lambda, as cost is not a major factor right now.
Autoscaling follows similar logic, allowing for 3 endpoint instances. Though because I don't expect heavy traffic for this endpoint, it does not need to be very reactive, hence the high scale cooldown times.